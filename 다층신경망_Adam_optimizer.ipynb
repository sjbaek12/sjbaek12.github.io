{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "다층신경망 Adam optimizer",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5hjzrnk/fP97woi3aeviS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjbaek12/sjbaek12.github.io/blob/master/%EB%8B%A4%EC%B8%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D_Adam_optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StMdI7ZzERr7",
        "colab_type": "text"
      },
      "source": [
        "다층 신경망 옵티마이저 입니다.\n",
        "텐서플로우 2.2 버전을 사용하고 저수준의 API를 이용하는 방법이다.\n",
        "저수준의 API를 사용할 경우, X data는 tf.Variable 형식으로 사용해야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqemfWz2Edji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e951b420-a9e3-4b8d-9a1d-2036b499111e"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify=y,test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size=0.2, random_state=42)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "y_train = y_train.reshape(364,1)\n",
        "x_train = tf.Variable(x_train, dtype=tf.float32) # 데이터를 tf Variable로 전환하였다\n",
        "print(x_train.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(364, 30) (364,)\n",
            "(364, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAGuaNrAsT1Y",
        "colab_type": "text"
      },
      "source": [
        "데이터 Normalization을 위한 함수이다.\n",
        "\n",
        "x_train은 tf.Variable로 만들어졌고, 데이터 정규화를 위한 np.mean axis=0 가 작동하지 않아서 numpy()를 사용해야 한다. axis = 0을 각 feature의 모든 샘플들의 평균을 구한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CBtdBsGiapy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_vals = np.mean(x_train.numpy(), axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc1RYRzbiV0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_val = np.std(x_train.numpy(), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2XBRHTJk545",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "15300067-ad18-49fe-a073-6ef464860e2a"
      },
      "source": [
        "std_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.5130656e+00, 4.4508610e+00, 2.4307308e+01, 3.4812045e+02,\n",
              "       1.3422389e-02, 5.4132197e-02, 8.3041109e-02, 3.9236300e-02,\n",
              "       2.7935697e-02, 7.2634481e-03, 2.7242586e-01, 5.4825425e-01,\n",
              "       2.0358245e+00, 4.3421593e+01, 3.1261286e-03, 1.8823136e-02,\n",
              "       3.4216441e-02, 6.4888443e-03, 8.9649800e-03, 2.8562618e-03,\n",
              "       4.8307662e+00, 6.3797069e+00, 3.3792259e+01, 5.6492914e+02,\n",
              "       2.2658244e-02, 1.6351485e-01, 2.2059496e-01, 6.7102090e-02,\n",
              "       6.4736947e-02, 1.8429259e-02], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpI7KRNRlK_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_centered = (x_train.numpy() - mean_vals) / std_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVKZ0TP7lZy_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "7f5093c5-c2e9-474f-8aa3-74633975fde6"
      },
      "source": [
        "x_train_centered[363]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.7439813 , -0.41000962, -0.73429614, -0.71486974,  0.9337152 ,\n",
              "       -0.21559933, -0.8699315 , -0.7867546 , -0.5990699 ,  0.3306867 ,\n",
              "       -0.4201    ,  1.2995043 , -0.4460087 , -0.41709974, -0.12901042,\n",
              "       -0.4790604 , -0.65113467, -0.3747566 ,  0.20070384, -0.12459129,\n",
              "       -0.7020968 ,  0.20052446, -0.7144869 , -0.64993083,  0.3768175 ,\n",
              "       -0.5004079 , -0.93843853, -0.77275336, -0.5248218 , -0.19926234],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ5ys6oBl7Yn",
        "colab_type": "text"
      },
      "source": [
        "아래는 함수를 만들어서 Normalize를 한 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zklLuxn9hJB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeNormal(x):\n",
        "  x = x.numpy()\n",
        "  xx_means= []\n",
        "  xx_stds = []\n",
        "  x_swap = np.swapaxes(x, 0,1)\n",
        "  for i in range(0,len(x_swap)):\n",
        "    x_c_mean = np.mean(x_swap[i])\n",
        "    xx_means.append(x_c_mean)\n",
        "    x_c_std = np.std(x_swap[i])\n",
        "    xx_stds.append(x_c_std)\n",
        "\n",
        "  xx_norm =[]\n",
        "  for i in range(0,len(x_swap)):\n",
        "    xx_normalized = (x_swap[i] - xx_means[i]) / xx_stds[i]\n",
        "    xx_norm.append(xx_normalized)\n",
        "  \n",
        "  xx_norm = np.swapaxes(xx_norm, 0,1)\n",
        "  return xx_norm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEvX8BT7scM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_norm = makeNormal(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjenfOJ6rb1X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "7b266e82-e81e-4a7b-a34c-f49fbb66c55d"
      },
      "source": [
        "x_train_norm[363]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.7439814 , -0.4100084 , -0.7342973 , -0.7148695 ,  0.9337174 ,\n",
              "       -0.21559939, -0.8699314 , -0.7867536 , -0.5990699 ,  0.33068886,\n",
              "       -0.42009923,  1.2995045 , -0.44600874, -0.41709962, -0.12900908,\n",
              "       -0.4790608 , -0.6511347 , -0.37475702,  0.2007028 , -0.12459145,\n",
              "       -0.70209754,  0.2005242 , -0.71448505, -0.64993066,  0.37681955,\n",
              "       -0.5004087 , -0.9384386 , -0.7727523 , -0.52482027, -0.1992591 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwR_TWvYmj7a",
        "colab_type": "text"
      },
      "source": [
        "numpy 형식으로 정규화된 데이터를 tf 형식으로 다시 바꿔서 텐서플로우에 적용해야 한다. 만약 정규화를 하지 않고, Adam 옵티마져를 그냥 적용하면 iteration 중간에 stop하는 결과가 나타났다. 그리고 초기값은 모두 zero를 적용하였다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5w2YGnImiQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_tf = tf.Variable(x_train_centered, dtype=tf.float32) # 정규화된 데이터를 다시 tf로 전환한다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pyzhlBxznNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiLayer():\n",
        "\n",
        "  def __init__(self):\n",
        "    # 가중치 변수는 tf로 초기값을 설정한다.\n",
        "    self.W1 = tf.Variable(np.zeros((30,20)), dtype=tf.float32)\n",
        "    self.b1 = tf.Variable(0.0, dtype=tf.float32)  # 초기치 설정을 다른 것으로 했을 때 error가 발생한 경우도 있었다.\n",
        "    self.W2 = tf.Variable(np.zeros((20,1)), dtype=tf.float32)\n",
        "    self.b2 = tf.Variable(0.0, dtype=tf.float32)\n",
        "    self.Wf1 = tf.Variable(np.zeros((30,20)), dtype=tf.float32)\n",
        "    self.bf1 = tf.Variable(0.0, dtype=tf.float32)\n",
        "    self.Wf2 = tf.Variable(np.zeros((20,1)), dtype=tf.float32)\n",
        "    self.bf2 = tf.Variable(0.0, dtype=tf.float32)\n",
        "    \n",
        "\n",
        "  def forword(self, x):\n",
        "    self.z1 = tf.matmul(x, self.W1) + self.b1\n",
        "    self.a1 = 1 / (1 + tf.exp(- self.z1))\n",
        "    self.z2 = tf.matmul(self.a1, self.W2) + self.b2 \n",
        "    a2 = 1 / (1 + tf.exp(- self.z2))   \n",
        "    return a2\n",
        "\n",
        "  def fit(self, x, y, num_epochs=1000):\n",
        "    losses = [] \n",
        "    self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001) # Adam을 쓰지않고 다른 것을 사용했을때 계산이 않되는 경우도 있었다.\n",
        "    for step in range(num_epochs):          \n",
        "      with tf.GradientTape() as tape:\n",
        "        a2 = self.forword(x)\n",
        "       # a2 = tf.clip_by_value(a2, 1e-10, 1-1e-10)\n",
        "       # t3 = tf.clip_by_value(t, clip_value_min=clip_min, clip_value_max=100)\n",
        "       # 자동 미분이 되는 대상은 tf로 표시된다.\n",
        "        loss = tf.reduce_sum(-(y*tf.math.log(a2) + (1-y)*tf.math.log(1-a2)))\n",
        "\n",
        "      grads = tape.gradient(loss, [self.W1, self.b1, self.W2, self.b2])\n",
        "      self.optimizer.apply_gradients(zip(grads, [self.W1, self.b1, self.W2, self.b2]))\n",
        "      losses.append(loss.numpy())\n",
        "      self.Wf1 = self.W1\n",
        "      self.bf1 = self.b1\n",
        "      self.Wf2 = self.W2\n",
        "      self.bf2 = self.b2\n",
        "    return losses \n",
        "\n",
        "  \n",
        "  def predict(self, x, y):\n",
        "    y_hat = []\n",
        "    zf1 = tf.matmul(x, self.Wf1) + self.bf1\n",
        "    af1 = 1 / (1 + tf.exp(-zf1)) \n",
        "    zf2 = tf.matmul(af1, self.Wf2) + self.bf2\n",
        "    af2 = 1 / (1 + tf.exp(-zf2))\n",
        "    for i in range(0, len(y)-1):\n",
        "      if af2[i] >= 0.5:\n",
        "          y_hat.append(1)\n",
        "      else:\n",
        "          y_hat.append(0)\n",
        "    return y_hat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY6SyuXK35hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mmodel = MultiLayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvvc7IsQ4Niu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = mmodel.fit(x_train_tf, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J32fg0j6BJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1887bf85-99c5-4164-b7e2-8aa7f142b219"
      },
      "source": [
        "print(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[252.3057, 251.80504, 251.29672, 250.77705, 250.245, 249.6997, 249.14056, 248.56693, 247.9784, 247.37444, 246.75471, 246.11884, 245.46652, 244.79759, 244.11183, 243.40913, 242.68945, 241.95279, 241.19922, 240.42886, 239.64186, 238.8385, 238.01901, 237.18369, 236.3329, 235.4671, 234.58662, 233.69206, 232.78392, 231.86275, 230.92924, 229.98404, 229.02783, 228.0614, 227.08545, 226.10081, 225.10826, 224.10864, 223.1028, 222.09146, 221.07558, 220.05592, 219.03333, 218.00864, 216.9826, 215.95609, 214.9298, 213.90446, 212.88084, 211.85962, 210.84143, 209.82687, 208.81662, 207.81116, 206.81102, 205.81673, 204.8287, 203.84738, 202.87314, 201.90633, 200.94731, 199.99634, 199.0537, 198.11961, 197.19432, 196.27798, 195.37079, 194.47285, 193.58427, 192.70523, 191.83568, 190.97578, 190.12558, 189.28502, 188.4542, 187.63306, 186.82164, 186.0199, 185.22777, 184.44525, 183.6723, 182.90883, 182.15482, 181.41019, 180.67482, 179.94865, 179.23164, 178.52367, 177.82465, 177.13445, 176.453, 175.78021, 175.11597, 174.46016, 173.81265, 173.17339, 172.5422, 171.91902, 171.3037, 170.69612, 170.0962, 169.5038, 168.91878, 168.34106, 167.77052, 167.20703, 166.65044, 166.10068, 165.5576, 165.02115, 164.49113, 163.9675, 163.45007, 162.9388, 162.43355, 161.93422, 161.44066, 160.95282, 160.47058, 159.99379, 159.52242, 159.05634, 158.59541, 158.13957, 157.68874, 157.2428, 156.80165, 156.36522, 155.9334, 155.5061, 155.08327, 154.6648, 154.25058, 153.84058, 153.43466, 153.03279, 152.63489, 152.24084, 151.85065, 151.46417, 151.08131, 150.70209, 150.32635, 149.95412, 149.58525, 149.21974, 148.85748, 148.49843, 148.14253, 147.78972, 147.43993, 147.09315, 146.74927, 146.40828, 146.07011, 145.7347, 145.40204, 145.07204, 144.74467, 144.41989, 144.09766, 143.77794, 143.46066, 143.14581, 142.83336, 142.52324, 142.21542, 141.90988, 141.60658, 141.3055, 141.00659, 140.7098, 140.41515, 140.12259, 139.83206, 139.5436, 139.25711, 138.97261, 138.69006, 138.40944, 138.1307, 137.8539, 137.57892, 137.3058, 137.0345, 136.765, 136.49725, 136.23131, 135.96707, 135.70457, 135.44377, 135.18468, 134.92723, 134.67146, 134.41731, 134.1648, 133.91386, 133.66454, 133.4168, 133.1706, 132.92595, 132.68285, 132.44122, 132.2011, 131.96248, 131.72533, 131.4896, 131.25534, 131.0225, 130.79109, 130.56104, 130.33238, 130.10509, 129.87917, 129.65457, 129.4313, 129.20934, 128.98868, 128.76929, 128.5512, 128.33435, 128.11873, 127.90436, 127.6912, 127.47923, 127.26848, 127.05887, 126.85044, 126.64317, 126.437035, 126.23203, 126.02814, 125.82533, 125.62363, 125.42299, 125.22344, 125.02494, 124.82749, 124.63106, 124.435646, 124.24124, 124.04783, 123.85542, 123.66399, 123.47352, 123.28401, 123.095436, 122.907814, 122.7211, 122.535324, 122.350426, 122.16646, 121.98336, 121.801155, 121.61979, 121.43932, 121.259674, 121.080894, 120.90294, 120.72581, 120.5495, 120.37401, 120.19931, 120.02541, 119.852295, 119.67996, 119.50839, 119.3376, 119.16756, 118.99826, 118.82969, 118.66187, 118.4948, 118.32841, 118.162766, 117.997826, 117.833565, 117.67003, 117.50717, 117.34499, 117.18348, 117.02265, 116.86247, 116.70298, 116.54412, 116.38592, 116.22833, 116.071396, 115.9151, 115.75942, 115.604355, 115.44991, 115.29607, 115.142845, 114.99021, 114.838165, 114.68671, 114.53584, 114.38555, 114.23585, 114.0867, 113.93811, 113.79009, 113.642624, 113.49571, 113.349335, 113.20351, 113.05823, 112.91348, 112.76926, 112.62556, 112.48238, 112.33972, 112.19758, 112.055954, 111.914825, 111.7742, 111.63407, 111.494446, 111.35529, 111.21662, 111.078476, 110.940765, 110.80356, 110.66682, 110.53054, 110.39474, 110.25939, 110.12451, 109.99009, 109.85611, 109.72258, 109.58952, 109.45687, 109.32467, 109.19292, 109.06161, 108.93071, 108.800255, 108.67021, 108.540596, 108.41141, 108.28262, 108.15427, 108.02631, 107.898766, 107.77163, 107.644875, 107.51856, 107.39262, 107.267075, 107.14193, 107.01718, 106.89281, 106.768814, 106.64522, 106.521996, 106.399155, 106.27669, 106.15459, 106.03286, 105.91151, 105.79051, 105.66988, 105.54963, 105.429726, 105.31018, 105.190994, 105.072136, 104.95366, 104.835526, 104.71774, 104.60028, 104.48318, 104.36641, 104.24999, 104.133896, 104.01814, 103.90272, 103.78763, 103.67287, 103.55844, 103.44432, 103.330536, 103.21707, 103.10393, 102.991104, 102.878586, 102.766396, 102.6545, 102.54294, 102.43166, 102.3207, 102.21006, 102.09972, 101.98967, 101.87991, 101.77047, 101.66132, 101.55246, 101.4439, 101.33564, 101.22766, 101.11998, 101.0126, 100.90549, 100.79866, 100.69211, 100.58585, 100.47988, 100.37417, 100.26875, 100.163605, 100.05873, 99.954124, 99.8498, 99.74574, 99.64197, 99.538445, 99.435196, 99.33221, 99.229485, 99.127014, 99.024826, 98.922874, 98.8212, 98.71979, 98.61862, 98.51771, 98.417046, 98.31665, 98.21649, 98.11659, 98.01693, 97.91752, 97.81835, 97.71945, 97.62078, 97.52234, 97.424164, 97.32622, 97.228516, 97.13104, 97.03381, 96.93681, 96.84006, 96.74354, 96.64724, 96.551186, 96.45536, 96.359764, 96.26439, 96.16925, 96.074326, 95.97964, 95.88518, 95.79093, 95.69692, 95.6031, 95.50953, 95.41617, 95.32304, 95.23011, 95.137405, 95.04492, 94.952644, 94.86058, 94.768745, 94.6771, 94.58568, 94.49446, 94.40346, 94.31266, 94.222084, 94.13169, 94.04152, 93.951546, 93.86178, 93.77222, 93.68285, 93.59368, 93.50474, 93.41596, 93.3274, 93.239044, 93.15087, 93.0629, 92.97511, 92.88754, 92.80016, 92.712975, 92.62597, 92.53916, 92.452545, 92.36611, 92.27987, 92.19381, 92.107956, 92.02227, 91.93678, 91.85149, 91.76637, 91.68142, 91.59667, 91.51211, 91.42771, 91.343506, 91.259476, 91.17564, 91.091965, 91.00846, 90.925156, 90.84202, 90.75905, 90.67628, 90.59366, 90.511215, 90.428955, 90.34687, 90.264946, 90.183205, 90.10162, 90.020226, 89.93898, 89.85792, 89.77701, 89.69628, 89.61572, 89.535324, 89.455086, 89.375015, 89.29511, 89.21536, 89.135796, 89.05638, 88.97712, 88.898026, 88.8191, 88.74033, 88.66171, 88.58326, 88.50496, 88.42681, 88.34884, 88.27102, 88.19336, 88.11584, 88.03848, 87.96129, 87.88423, 87.807335, 87.73058, 87.65399, 87.57755, 87.50126, 87.425125, 87.34914, 87.2733, 87.1976, 87.122055, 87.04666, 86.97141, 86.896324, 86.82136, 86.74655, 86.67189, 86.59735, 86.522995, 86.44876, 86.37468, 86.30071, 86.22692, 86.15325, 86.07974, 86.006355, 85.93311, 85.860016, 85.78705, 85.71422, 85.64153, 85.56898, 85.49657, 85.42431, 85.352165, 85.28016, 85.2083, 85.136566, 85.06498, 84.9935, 84.92217, 84.850975, 84.77991, 84.708984, 84.63818, 84.56751, 84.49698, 84.42656, 84.35629, 84.28615, 84.216125, 84.14624, 84.07648, 84.006836, 83.93734, 83.86796, 83.798706, 83.72958, 83.66057, 83.5917, 83.52294, 83.45431, 83.38582, 83.31744, 83.24917, 83.181046, 83.11304, 83.04514, 82.97738, 82.90974, 82.84222, 82.77481, 82.70753, 82.64036, 82.57331, 82.5064, 82.43958, 82.37289, 82.30631, 82.23987, 82.173515, 82.10731, 82.04121, 81.97521, 81.909355, 81.84359, 81.777954, 81.71242, 81.647, 81.58172, 81.51653, 81.451454, 81.38649, 81.32165, 81.25691, 81.19228, 81.12776, 81.063354, 80.99907, 80.93488, 80.87081, 80.80686, 80.743, 80.679245, 80.61562, 80.55209, 80.48868, 80.42536, 80.36216, 80.299065, 80.23608, 80.17317, 80.11041, 80.04773, 79.98516, 79.92271, 79.860344, 79.798096, 79.73593, 79.67389, 79.61194, 79.55011, 79.48838, 79.426735, 79.3652, 79.30377, 79.24244, 79.18122, 79.12008, 79.05906, 78.99812, 78.9373, 78.876564, 78.81595, 78.75542, 78.69498, 78.63467, 78.574425, 78.5143, 78.45425, 78.39431, 78.33447, 78.27473, 78.21507, 78.15552, 78.09608, 78.036705, 77.97744, 77.91827, 77.859184, 77.8002, 77.74132, 77.68253, 77.623825, 77.56522, 77.50671, 77.448296, 77.38996, 77.33172, 77.27358, 77.21554, 77.15758, 77.09972, 77.04193, 76.98424, 76.92666, 76.86915, 76.81174, 76.75441, 76.69718, 76.64004, 76.58297, 76.526, 76.469124, 76.41234, 76.35563, 76.29902, 76.242485, 76.18604, 76.129684, 76.07343, 76.01725, 75.96115, 75.90515, 75.84922, 75.79339, 75.737625, 75.68197, 75.62638, 75.57089, 75.51548, 75.46015, 75.40491, 75.34975, 75.29466, 75.23968, 75.18477, 75.129944, 75.07521, 75.02054, 74.965965, 74.911446, 74.85705, 74.802704, 74.74844, 74.69428, 74.64019, 74.58617, 74.53224, 74.47839, 74.42462, 74.370926, 74.31732, 74.26378, 74.21033, 74.15695, 74.10365, 74.05044, 73.99729, 73.944244, 73.89125, 73.83835, 73.78552, 73.73277, 73.6801, 73.6275, 73.57498, 73.52253, 73.47016, 73.417885, 73.36566, 73.313515, 73.26145, 73.20945, 73.15755, 73.105705, 73.05394, 73.00224, 72.95064, 72.899086, 72.84762, 72.79622, 72.74489, 72.69364, 72.64246, 72.59137, 72.54033, 72.48938, 72.438484, 72.38766, 72.33693, 72.28627, 72.23567, 72.185135, 72.13468, 72.084305, 72.03398, 71.983734, 71.93357, 71.88345, 71.83342, 71.783455, 71.73356, 71.68372, 71.63399, 71.584305, 71.53468, 71.485146, 71.43566, 71.38625, 71.33691, 71.28763, 71.23843, 71.189285, 71.14021, 71.0912, 71.04227, 70.9934, 70.9446, 70.895874, 70.847206, 70.7986, 70.75005, 70.7016, 70.653175, 70.60485, 70.55658, 70.50837, 70.460236, 70.41215, 70.364136, 70.31619, 70.26831, 70.22049, 70.17274, 70.125046, 70.07743, 70.02987, 69.98236, 69.934944, 69.887566, 69.840256, 69.793015, 69.74583, 69.69872, 69.65166, 69.60467, 69.55774, 69.51087, 69.464066, 69.41733, 69.370636, 69.32402, 69.27744, 69.23096, 69.184525, 69.13815, 69.09183, 69.045586, 68.999374, 68.953255, 68.90717, 68.861176, 68.8152, 68.76931, 68.72348, 68.677704, 68.63199, 68.586334, 68.54073, 68.4952, 68.449715, 68.404305, 68.35894, 68.31364, 68.268394, 68.223206, 68.17807, 68.13301, 68.08799, 68.04304, 67.99813, 67.9533, 67.90851, 67.863785, 67.819115, 67.774506, 67.72996, 67.68545, 67.641014, 67.59661, 67.55229, 67.50802, 67.46379, 67.41963, 67.37553, 67.33147, 67.28748, 67.243546, 67.19965, 67.155815, 67.11205, 67.06832, 67.02466, 66.98105, 66.93748, 66.89399, 66.85054, 66.80714, 66.7638, 66.720505, 66.67727, 66.634094, 66.590965, 66.54789, 66.50487, 66.46191, 66.41898, 66.37613, 66.33332, 66.290565, 66.247856, 66.20521, 66.16261, 66.12006, 66.07756, 66.035126, 65.992714, 65.950386, 65.908104, 65.86587, 65.82368, 65.78153, 65.739456, 65.69742, 65.65543, 65.613495, 65.571625, 65.52979, 65.488, 65.44629, 65.404594, 65.36298, 65.3214, 65.27987, 65.23838, 65.19696, 65.15557, 65.11425, 65.07297, 65.03174, 64.99054, 64.94941, 64.90833, 64.86728, 64.826294, 64.78535, 64.74445, 64.70362, 64.66283, 64.62208, 64.58137, 64.540726, 64.50013, 64.45956, 64.41907, 64.37859, 64.33818, 64.29782, 64.2575, 64.217224, 64.177, 64.13683, 64.096695, 64.05662, 64.01658, 63.97657, 63.93663, 63.896744, 63.856895, 63.817078, 63.777332, 63.737614, 63.697937, 63.658325, 63.61873, 63.579205, 63.539726, 63.50029, 63.4609, 63.421543]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5iVEPXr6BSE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ab84aea4-d353-4e22-c144-afe29fde1b2c"
      },
      "source": [
        "plt.plot(losses, label = \"train\")\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSP62toP6LWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9bac11e7-8346-48f9-90ee-c95e439c1f61"
      },
      "source": [
        "y_hat = mmodel.predict(x_train_tf, y_train)\n",
        "print(y_hat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YFzryR6vw3X",
        "colab_type": "text"
      },
      "source": [
        "training set의 분류 정확도는 0.98이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdGQVetv6Lc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c263425-c9b6-4b34-a8da-19ead1a41412"
      },
      "source": [
        "score = 0.0\n",
        "\n",
        "for i in range(0, len(y_train)-1):\n",
        "  if y_hat[i] == y_train[i]:\n",
        "    score = score + 1\n",
        "    \n",
        "score = score/len(y_train)\n",
        "\n",
        "print(\"score is \", score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "score is  0.9835164835164835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5j2GRKkw5TP",
        "colab_type": "text"
      },
      "source": [
        "이제 전혀 다른 방법으로 \n",
        "**상기과정을 Sequential Model로 전환하여 시행해 본다**\n",
        "**데이터 관점에서 보면 Sequential Model을 사용할 경우 X data를 numpy로 그냥 써도 된다  **\n",
        "**고수준 모델에서는 Class를 사용하지 않고 일반적인 함수로도 충분하다**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPVlfwe60con",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "22c0ac59-b38d-4b36-b3b5-d1932b84b49a"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cancer = load_breast_cancer()\n",
        "x = cancer.data\n",
        "y = cancer.target\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify=y,test_size=0.2, random_state=42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size=0.2, random_state=42)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "y_train = y_train.reshape(364,1)\n",
        "print(x_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(364, 30) (364,)\n",
            "(364, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOLdOOQg4vCc",
        "colab_type": "text"
      },
      "source": [
        "여기서는 x_train_centered를 tf.Variable로 전환하지 않았다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WcXIdmK4Zh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_vals = np.mean(x_train, axis=0) \n",
        "std_val = np.std(x_train, axis=0)\n",
        "x_train_centered = (x_train - mean_vals) / std_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezITQ6JfwWq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ouK6ZEjwatR",
        "colab_type": "text"
      },
      "source": [
        "**이전 모델과의 차이점은 weight의 초기치를 glorot_uniform을 쓴다는 것이다.**\n",
        " 초기값의 기본설정은 다음과 같다 kernel_initializer='glorot_uniform'\n",
        "activation이 옵션으로는 relu, softmax, sigmoid, tanh 등이 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gl2ckM1xjiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(\n",
        "    units=20,\n",
        "    input_dim=x_train_centered.shape[1],\n",
        "    #kernel_initializer='glorot_uniform',\n",
        "    kernel_initializer='zero',\n",
        "    bias_initializer='zero',\n",
        "    activation =\"sigmoid\"))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(\n",
        "    units=y_train.shape[1],\n",
        "    input_dim=20,\n",
        "    #kernel_initializer='glorot_uniform',\n",
        "    kernel_initializer='zero',\n",
        "    bias_initializer='zero',\n",
        "    activation = \"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEA4yfcxyoAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "3ab1b778-f8a7-4f7c-b49d-16c280da0f87"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 641\n",
            "Trainable params: 641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNax0B-IzKT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjjBIFMLzixd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16a1932c-ead7-422c-8847-694882e49e79"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6822\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6553\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.6133\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5779\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5457\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.5131\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4969\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4849\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4678\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4545\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4477\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4649\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4351\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4277\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4181\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4183\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.4055\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3971\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3942\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3903\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3818\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3893\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3684\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3744\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3713\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3679\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3634\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3639\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3468\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3441\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3407\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3430\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3561\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3472\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3326\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3312\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3375\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3349\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3507\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3252\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3181\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3266\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3223\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3095\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3116\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3208\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3175\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3266\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3118\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3060\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3004\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2931\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2961\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2893\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2920\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2965\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3083\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3195\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2939\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2869\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2792\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2768\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2818\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2747\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2715\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2703\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2701\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2781\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2659\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2676\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2765\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2619\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2608\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2723\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2593\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2590\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.3138\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2678\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2860\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2592\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2661\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2519\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2505\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2481\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2637\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2981\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2717\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2730\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2388\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2458\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2460\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2512\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2464\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2320\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2883\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2586\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2775\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2510\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2347\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2405\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2438\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2393\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2265\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2227\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2241\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2273\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2284\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2243\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2289\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2660\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2336\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2311\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2378\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2164\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2162\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2359\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2271\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2256\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2132\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2135\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2154\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2453\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2251\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2121\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2353\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2096\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2135\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2039\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2131\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2092\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2124\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2106\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2035\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2036\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2247\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2456\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2004\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1987\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2098\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1918\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2033\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1952\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2044\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1927\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1920\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1888\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1861\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2432\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2600\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1999\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1912\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2071\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2071\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1927\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1934\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1967\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1907\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1971\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2195\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2380\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1917\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2018\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2172\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1876\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1767\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1847\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1930\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1877\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1761\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1944\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1722\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1804\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1914\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2073\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1848\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1869\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2077\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1705\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1742\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1867\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2102\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2335\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2258\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2461\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1703\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1884\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1641\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1807\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1638\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2046\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1856\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1780\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1599\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1874\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1589\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1616\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1610\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1654\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1613\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1549\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1595\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1890\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2191\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1864\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1698\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1588\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1682\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1564\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1515\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1654\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1672\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1541\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1470\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1747\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1686\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1808\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1555\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1476\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1497\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1674\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1536\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1672\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1570\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1594\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1609\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1572\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1519\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1500\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1548\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1467\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1449\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1422\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1471\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1467\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1534\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1411\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1428\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1537\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1520\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1423\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1455\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1457\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1619\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1689\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1651\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1340\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1569\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1384\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1626\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1715\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1406\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1385\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1400\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1463\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1455\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1396\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1411\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1608\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1859\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1527\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1517\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1580\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1436\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1302\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1402\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1437\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1447\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1371\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1346\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1436\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1485\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1419\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1387\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1314\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1262\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1249\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1382\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1304\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1271\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1337\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1358\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1398\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1309\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1263\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1228\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1467\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1478\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1202\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1303\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1240\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1356\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1210\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1263\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1534\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1465\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1225\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1218\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1439\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1491\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1502\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1184\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1201\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1339\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1780\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2170\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1483\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1522\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1572\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1730\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1488\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1362\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1477\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1369\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1301\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1451\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1268\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1483\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1197\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1755\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1677\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1380\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1323\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1434\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1210\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1244\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1389\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1178\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1644\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1203\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1166\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1128\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1170\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1137\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1257\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1411\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1183\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1455\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1189\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1183\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1313\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1457\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1363\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1408\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1169\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1144\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1101\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1235\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1099\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1117\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1104\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1200\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1149\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1165\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1087\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1094\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1079\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1212\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1220\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1446\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1263\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1110\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1096\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1241\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1144\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1109\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1289\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1471\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1283\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1101\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1154\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1149\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1658\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1344\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1348\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1215\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1019\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1027\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1137\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1081\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1030\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1118\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1122\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1007\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1115\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1360\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1436\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1061\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1242\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1197\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1065\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1218\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1037\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1206\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1141\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1069\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1054\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1103\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1134\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1754\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.2030\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1747\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2151\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1647\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1109\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1144\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1001\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1043\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1247\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1214\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1047\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0980\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1051\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1037\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1446\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1312\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1232\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1050\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1375\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1026\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1039\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1007\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1302\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1742\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1352\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1358\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1276\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1308\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1199\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1110\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1164\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1000\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1048\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1051\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0946\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1014\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1010\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1081\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1437\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0978\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1123\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1015\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1022\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1063\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0959\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1007\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0981\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0998\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1030\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0988\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0937\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0986\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1040\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1549\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1433\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1698\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1349\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1057\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1016\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1057\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1073\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0979\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1004\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0981\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1035\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0961\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1120\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1071\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1105\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1188\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0986\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0930\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0907\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0916\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1003\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0955\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0971\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0942\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1234\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1095\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0981\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0919\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0966\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0953\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0910\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0929\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0981\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1008\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1013\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1196\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1157\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1182\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1127\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1095\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1281\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1143\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0910\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1022\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0882\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1067\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0931\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0939\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1059\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1033\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0895\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0929\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0930\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0909\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0928\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0860\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0897\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0932\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0949\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0891\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0995\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0991\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0891\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0923\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0848\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0911\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1335\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1234\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1304\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0894\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0978\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0871\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0951\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1328\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1404\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1486\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1419\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1301\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1100\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1255\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1047\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1030\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0983\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1032\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1386\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1000\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1126\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1839\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1802\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1668\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1499\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1287\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0938\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0885\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0926\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0889\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0995\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0899\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0840\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0895\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0879\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0894\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0997\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0870\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0862\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0966\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0946\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0935\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0879\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0970\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0831\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0876\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0926\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1047\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0857\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0861\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0883\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0852\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0901\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0866\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0896\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0891\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0966\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0972\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0854\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0863\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1253\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1130\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0958\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0866\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0797\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0968\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1001\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1166\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0863\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1112\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0977\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0935\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1018\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0830\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0894\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1117\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1259\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0833\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0881\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0899\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0807\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0894\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0852\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0976\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1005\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0964\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0928\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1017\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1021\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0810\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0860\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0813\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0899\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0896\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0911\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0942\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0816\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0845\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0804\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0903\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0806\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0768\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0825\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0890\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1109\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1004\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0849\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1145\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1141\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0896\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0800\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0844\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0805\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0921\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0806\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0779\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0917\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0861\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1022\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0747\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0981\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0799\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0980\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1375\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0908\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1012\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0947\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0833\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1013\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0789\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1031\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0900\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0857\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0818\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0724\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0818\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1248\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1744\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1201\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0949\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0845\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0781\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0991\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0854\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0810\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0836\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0752\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0879\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1115\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0855\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0972\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0821\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0859\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0808\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0878\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0838\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0769\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0965\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0880\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0775\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0842\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1673\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0822\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1373\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0971\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0914\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1210\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0832\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0842\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1043\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0875\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0985\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0908\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0848\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1068\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0952\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1124\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1042\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0944\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0833\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0824\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0885\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0895\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0771\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0827\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0801\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0759\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0777\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0821\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0860\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0795\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0830\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0785\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0850\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0752\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0828\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0823\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0746\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0811\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0850\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0861\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0810\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0751\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0743\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0825\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0972\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1027\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1035\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0875\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0867\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0791\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0795\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0985\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1008\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1202\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0768\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1048\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1058\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0807\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1103\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1449\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1102\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0761\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0781\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0709\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1183\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1494\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0759\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0846\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0773\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0875\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0871\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0868\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1104\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0770\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0957\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0797\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0874\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0806\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0752\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0785\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0958\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0817\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1218\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0998\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0806\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0775\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0755\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0728\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0894\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0781\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0717\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0749\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0848\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1101\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0856\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0684\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0887\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0733\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0799\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0848\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0908\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1015\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1172\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1031\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1015\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0777\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0778\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1315\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0844\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0844\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0749\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0737\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0727\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0792\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0846\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0812\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0929\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0933\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0740\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0738\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0896\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1116\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0973\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0731\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0827\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1059\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0743\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0759\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0765\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0728\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0938\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0886\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0743\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0972\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1812\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1106\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1134\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0866\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0877\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0975\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0900\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0931\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0766\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0806\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0774\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0748\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0770\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0747\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0748\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0825\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0710\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0966\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0746\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0734\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0730\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0748\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0833\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0894\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0968\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0985\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1341\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0909\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0722\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0914\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0839\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0726\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0713\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0725\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0695\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0736\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0788\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1069\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0850\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1369\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1066\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0924\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1042\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0947\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0924\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0795\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0976\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0885\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0921\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0801\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0725\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0707\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0721\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0685\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0748\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0750\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0788\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0998\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1417\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0885\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0710\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0701\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0743\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0786\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1137\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1197\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1178\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0882\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0760\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0712\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0750\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0806\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0738\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0674\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0698\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0676\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0937\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0643\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0815\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1090\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0765\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0998\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0996\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0808\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0780\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0807\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0768\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0920\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1286\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0792\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0988\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0845\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0823\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0969\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0843\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0735\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0682\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0690\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0752\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0676\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0746\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0961\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0897\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0872\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0789\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0686\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0835\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0611\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1069\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0712\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0812\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0883\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0973\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0915\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1094\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1397\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0781\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.1079\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0992\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0755\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0703\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0786\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0915\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0834\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0793\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0734\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0967\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0862\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0774\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0706\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0692\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0726\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0727\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0704\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0680\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0661\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0702\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0821\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0769\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0682\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0822\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0891\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0704\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0696\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1140\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0768\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0842\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0742\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0694\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0651\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0778\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0755\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0742\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0756\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0722\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0711\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0796\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0803\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0769\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0704\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0744\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0678\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0684\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0709\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0708\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0707\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0692\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0688\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0724\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0831\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0756\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0791\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0659\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0714\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0862\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0979\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0893\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0804\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0677\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0735\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0730\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.0819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Gd7_j_0zKg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "db5ad569-6ae6-46aa-b229-395aefe7c9e1"
      },
      "source": [
        "epochs = np.arange(1, 1000+1)\n",
        "plt.plot(epochs, history.history['loss'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe730e104a8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgyZDB3NjUjf",
        "colab_type": "text"
      },
      "source": [
        "model.predict는 값자체를 예측하고, model.predict_classes는 1,0 등 분류데이터로 예측을 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0QOpecr7kbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred = model.predict_classes(x_train_centered) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIAZX8gY77RM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correc_preds = np.sum(y_train == y_train_pred, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQlu3zvX8bsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "958f0895-a274-41ad-b9a1-88c82d46940c"
      },
      "source": [
        "print(\"정확도는  \", correc_preds / y_train.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "정확도는   [0.89285714]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJtk2CB29s4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('mlp_weight.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg9Woc5ZH2kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W_Input_Hidden = model.layers[0].get_weights()[0] # 첫번째 Layer의 weight를 가져오는 방법이다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Yv2moUH7Py",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80acf0f8-e87b-4779-e6e4-77873c12f94e"
      },
      "source": [
        "print(W_Input_Hidden)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2.48989433e-01 -4.84146886e-02  1.68191075e-01  1.44767821e-01\n",
            "   2.41171062e-01 -3.50050330e-02  2.27494746e-01  3.09381187e-02\n",
            "   1.03873074e-01 -1.07410744e-01  2.66996115e-01  2.06619993e-01\n",
            "   2.81836212e-01  3.10609996e-01  3.23907018e-01  1.33269042e-01\n",
            "   3.26643348e-01 -1.07562467e-01 -2.34670505e-01 -1.56586021e-01]\n",
            " [-3.38367760e-01 -1.13012508e-01 -3.00682217e-01 -2.33388126e-01\n",
            "   1.83026955e-01  2.11466551e-02  1.55122757e-01  5.39049208e-02\n",
            "  -2.60606170e-01 -3.16739798e-01  5.36584035e-02 -1.09058142e-01\n",
            "   2.04704404e-01  1.70388341e-01 -2.08519921e-01  2.67397225e-01\n",
            "   1.87040687e-01 -1.95498273e-01  1.12425745e-01 -2.39749908e-01]\n",
            " [ 1.68604124e-02 -3.24964583e-01  3.27028453e-01  2.57922053e-01\n",
            "   1.26956642e-01  2.71367192e-01  1.30686283e-01 -1.54437929e-01\n",
            "  -2.73438543e-01  1.16188645e-01 -1.32074272e-02  2.03805089e-01\n",
            "   1.88692451e-01 -2.47932076e-02 -1.25590757e-01  2.76374519e-02\n",
            "  -2.64285594e-01 -1.82769239e-01  1.47345960e-01  2.26954401e-01]\n",
            " [-2.83601135e-01 -5.33126071e-02  3.26615512e-01 -1.76918972e-02\n",
            "   2.25038290e-01 -2.92208999e-01 -1.39513239e-01  3.14325452e-01\n",
            "  -3.11952859e-01  1.09101117e-01  1.73814908e-01 -2.28065625e-01\n",
            "   3.37177575e-01  3.04464698e-01  3.48948538e-02  1.41080290e-01\n",
            "   3.23259234e-01  2.42594182e-02 -5.98609447e-02 -3.79157960e-02]\n",
            " [-1.97987810e-01  6.13413155e-01 -3.22137117e-01 -4.98053730e-02\n",
            "  -2.02103034e-01 -2.13676468e-01  5.39917089e-02 -1.47641793e-01\n",
            "  -1.30111769e-01  2.89237022e-01 -2.25422621e-01 -3.69301915e-01\n",
            "   2.35556304e-01  5.48532307e-02  2.29682922e-02  1.21391267e-01\n",
            "   3.15194964e-01  3.46644521e-02 -1.06792063e-01 -1.33496746e-01]\n",
            " [ 7.72329211e-01  3.22276664e+00  1.14464968e-01 -1.19391590e-01\n",
            "   3.47611606e-02 -8.59535336e-02 -3.36498737e-01  3.05239260e-02\n",
            "   1.17509842e-01  1.11282438e-01 -4.01785344e-01 -3.09366405e-01\n",
            "  -1.63602680e-01 -4.47420776e-02 -2.79270351e-01  3.15526366e-01\n",
            "  -2.75267959e-02 -2.79869705e-01  2.47274339e-01 -1.64204106e-01]\n",
            " [ 1.13989890e+00  4.31901360e+00 -4.30200398e-02 -1.17570475e-01\n",
            "  -1.04208708e-01 -1.89753756e-01  5.71094528e-02  2.72525609e-01\n",
            "   3.01778257e-01  1.79553628e-02  9.59243178e-02 -2.30491921e-01\n",
            "   1.60524845e-02  1.11727774e-01  2.46634901e-01  1.22243524e-01\n",
            "  -2.97719836e-01 -1.31983116e-01  1.06467158e-01 -3.39637548e-01]\n",
            " [ 2.61546564e+00  3.48871112e+00  2.40100086e-01  3.13497365e-01\n",
            "   2.43885219e-01  2.15414464e-02  1.78054109e-01 -1.77673981e-01\n",
            "  -1.53511167e-02 -3.07677716e-01 -3.19963753e-01 -2.89653949e-02\n",
            "   1.51156932e-01 -3.31554830e-01  2.16353953e-01 -1.67161226e-04\n",
            "   3.94449532e-02  2.94087946e-01 -7.58589804e-02  1.87510192e-01]\n",
            " [-8.95854905e-02  4.27422881e-01 -3.19843054e-01 -5.90928495e-02\n",
            "   8.33024681e-02  1.31456256e-02 -3.10708731e-01 -1.38981044e-02\n",
            "   3.07762682e-01 -8.57227743e-02  2.21862808e-01 -3.22827429e-01\n",
            "  -5.09831905e-02  2.49365449e-01 -7.65860081e-04 -1.27995059e-01\n",
            "  -1.10141024e-01 -2.75116116e-01  4.45473194e-02 -6.04906976e-02]\n",
            " [-5.75995564e-01  2.63224036e-01 -6.60167336e-02 -2.13204369e-01\n",
            "   2.76048720e-01  1.10927612e-01  8.26479495e-02  9.02208388e-02\n",
            "  -1.09995902e-02 -1.31110296e-01  1.79753918e-02 -1.20996341e-01\n",
            "  -2.27062017e-01 -3.07346761e-01  1.17001414e-01  2.12835073e-02\n",
            "  -2.47094527e-01  1.42109036e-01  2.38248408e-01  1.58268571e-01]\n",
            " [-6.93514705e-01 -6.31959260e-01  2.56746709e-01 -2.05848932e-01\n",
            "  -7.37374127e-02  2.41318345e-02 -2.40819216e-01  3.14195693e-01\n",
            "  -2.79365718e-01 -1.30377963e-01 -1.42643556e-01  1.24562040e-01\n",
            "   2.26118743e-01  1.94230080e-01 -4.10968363e-02  1.73035681e-01\n",
            "   1.42956078e-02  1.14657819e-01 -2.04438269e-02  2.98794091e-01]\n",
            " [ 1.20605761e-03  1.00894541e-01  2.23614335e-01  1.68438554e-02\n",
            "   3.02695930e-01 -1.27890706e-03 -1.35476068e-01  7.10530281e-02\n",
            "   2.59819686e-01 -3.73066068e-02  8.10092613e-02  1.80422198e-02\n",
            "  -7.09105730e-02  6.00693822e-02  3.01806688e-01  1.35821342e-01\n",
            "  -2.75485307e-01 -1.51257202e-01  2.01018512e-01  1.82822526e-01]\n",
            " [ 1.44875169e-01  5.80496132e-01  1.82208955e-01  2.69227922e-02\n",
            "   2.33157337e-01 -2.56508589e-03 -3.09216291e-01 -2.51653790e-01\n",
            "   1.28570139e-01 -1.31002098e-01  1.48154378e-01 -1.10116288e-01\n",
            "  -1.65399268e-01  1.62160099e-02 -1.13439858e-02  2.22247660e-01\n",
            "   2.51089871e-01  2.36781776e-01 -1.62894547e-01 -2.03019977e-02]\n",
            " [ 4.24885601e-01 -1.34598520e-02  3.22524965e-01  8.87218118e-02\n",
            "   5.17887473e-02  7.70364702e-02  2.60830760e-01  1.69135034e-01\n",
            "  -6.64893389e-02  5.89510202e-02  1.82645679e-01 -5.36969677e-03\n",
            "  -2.89867550e-01 -2.54395604e-02  2.59626150e-01  1.19546026e-01\n",
            "  -1.92379728e-01 -2.66907692e-01 -1.49159640e-01  1.83379829e-01]\n",
            " [-8.48868847e-01  1.36787260e+00  4.52950895e-02 -2.51212746e-01\n",
            "  -1.50221184e-01  1.25369906e-01  1.37673259e-01 -1.28982916e-01\n",
            "  -1.47956967e-01  1.30691141e-01 -4.73595224e-02  2.49210760e-01\n",
            "  -2.54144132e-01  2.60604918e-01 -3.07495922e-01 -1.68418050e-01\n",
            "  -2.39808470e-01  1.93930447e-01  2.82297313e-01 -2.63794750e-01]\n",
            " [-8.19415212e-01  3.14270806e+00  6.11608326e-02 -2.37337351e-01\n",
            "  -1.22519210e-01  2.73606539e-01  1.39764845e-01 -1.57862470e-01\n",
            "  -1.93588853e-01 -2.67187238e-01  2.13261589e-01 -1.64429955e-02\n",
            "   2.53965139e-01 -2.20551804e-01  2.00689554e-01  3.32942367e-01\n",
            "  -2.75324643e-01  3.29209089e-01 -2.87183017e-01 -1.04272395e-01]\n",
            " [-2.12328577e+00  3.38828015e+00  2.73210764e-01 -2.05381885e-01\n",
            "   8.52981806e-02 -2.84737825e-01 -1.37948431e-02  1.71877444e-01\n",
            "   2.24018395e-01 -2.26234376e-01  1.15473032e-01 -2.39869267e-01\n",
            "   1.88148856e-01  8.86444151e-02 -6.88004494e-03 -2.84319013e-01\n",
            "   2.37202048e-02 -1.99975923e-01  2.76841521e-01 -1.63513482e-01]\n",
            " [-5.15057027e-01  2.92118096e+00  1.74963176e-01  1.83288157e-01\n",
            "   2.73143768e-01  5.59107959e-02  4.29812483e-02 -2.47152597e-01\n",
            "  -1.55484676e-03  3.00445974e-01 -2.79351741e-01 -1.70251265e-01\n",
            "  -2.03135177e-01 -9.84011889e-02  1.90007329e-01 -1.02967456e-01\n",
            "  -2.51014441e-01 -2.61400223e-01 -7.85791874e-02 -1.96519256e-01]\n",
            " [-7.63178349e-01  1.55623937e+00 -2.87852347e-01  1.15238696e-01\n",
            "   6.69175684e-02  1.76707506e-01  7.07634492e-03  1.06311142e-01\n",
            "   2.53857791e-01  2.86761045e-01  2.49370590e-01 -3.15454006e-01\n",
            "  -9.98569280e-02  2.81910598e-02  1.34504259e-01 -3.40130627e-01\n",
            "  -7.66059458e-02  6.49026930e-02 -2.33018190e-01 -2.72325546e-01]\n",
            " [-2.18631101e+00  1.46461248e+00  1.90821230e-01  8.88395309e-03\n",
            "   1.26227289e-01 -6.06445670e-02  1.01160079e-01  8.01927745e-02\n",
            "   2.07231641e-01  2.52737045e-01  2.25959361e-01  2.65240580e-01\n",
            "  -1.05306506e-01 -7.93715715e-02 -1.43284142e-01 -1.51335001e-02\n",
            "  -4.18597460e-02 -2.71490544e-01 -1.67847276e-02  1.39674842e-01]\n",
            " [-3.66939008e-01 -5.86442709e-01  9.63097513e-02  2.77404070e-01\n",
            "   9.80302393e-02 -3.93099189e-02 -2.55010307e-01  2.02450693e-01\n",
            "   1.26503974e-01  7.44950771e-03  1.43674165e-01  2.18650311e-01\n",
            "  -2.13643089e-01 -2.57835776e-01  2.49076545e-01  3.15649509e-01\n",
            "  -2.58668274e-01  3.30003798e-01 -7.60602653e-02 -3.27181071e-01]\n",
            " [ 5.11967242e-01  2.18756586e-01 -2.82458991e-01  4.69893515e-02\n",
            "  -2.08783329e-01  3.06417048e-02 -3.15917999e-01  1.35423422e-01\n",
            "  -8.26180279e-02 -3.08559239e-02  7.17258230e-02  5.45835197e-02\n",
            "  -1.58141628e-01  5.07388711e-02 -3.22105646e-01  2.67836154e-01\n",
            "   2.23376215e-01 -2.96676219e-01  2.98785567e-02 -1.60126776e-01]\n",
            " [-4.28834051e-01 -2.99354553e-01  3.19438517e-01  1.76251709e-01\n",
            "  -3.94283719e-02 -3.28258723e-01  1.75860167e-01  2.82137334e-01\n",
            "   1.83325708e-02 -1.52050257e-02 -2.21997127e-01  1.09261572e-01\n",
            "   7.58383274e-02 -3.48821282e-03  1.22485161e-02 -8.09470713e-02\n",
            "   3.48040164e-02  3.36016357e-01  1.05148256e-01 -2.28530973e-01]\n",
            " [ 2.53769845e-01  1.26384944e-01  6.73093796e-02 -2.38049239e-01\n",
            "  -3.38778377e-01 -1.23579100e-01 -2.83626989e-02  3.35548341e-01\n",
            "  -1.68175310e-01  1.37698889e-01 -2.73039013e-01  3.62473242e-02\n",
            "   2.83885896e-01  5.72882295e-02  2.24400759e-01  6.32125437e-02\n",
            "   1.22826785e-01 -2.69765973e-01  1.02042347e-01 -1.49432033e-01]\n",
            " [ 5.29362619e-01  5.49328923e-01 -3.39377314e-01 -3.41263026e-01\n",
            "   3.29700351e-01  5.15219271e-02 -1.19422823e-01  1.07862860e-01\n",
            "  -7.76066184e-02 -3.89412344e-02 -3.04703087e-01  3.96403708e-02\n",
            "   1.27376527e-01 -2.86553442e-01  2.20682025e-01 -2.58158356e-01\n",
            "  -2.07988277e-01  8.83703232e-02  8.29994678e-05 -3.11007500e-02]\n",
            " [ 1.85050344e+00  3.68825412e+00  2.97376335e-01  1.68889225e-01\n",
            "  -4.52629626e-02 -1.63206324e-01  9.39650014e-02 -2.08517194e-01\n",
            "  -2.07479104e-01 -2.79595584e-01 -3.41128111e-02 -1.69118240e-01\n",
            "   2.69324303e-01  2.13012278e-01 -1.74367547e-01  3.21556926e-01\n",
            "   1.48554593e-01 -1.03788659e-01 -1.39244393e-01 -1.04720697e-01]\n",
            " [ 1.25568128e+00  4.30931568e+00  1.49318039e-01  9.15264189e-02\n",
            "  -2.04006255e-01 -1.27590522e-01 -7.31296018e-02  2.92194128e-01\n",
            "  -1.80777311e-01 -2.02696785e-01 -2.52062231e-01  1.86888441e-01\n",
            "  -2.57396996e-02  1.09848410e-01  3.31898093e-01 -3.19061667e-01\n",
            "   1.05026037e-01 -2.78931975e-01  2.92155981e-01  3.13623011e-01]\n",
            " [ 1.17240369e+00  3.36813116e+00  1.48867935e-01 -1.78159937e-01\n",
            "  -6.71584010e-02  7.31569529e-02 -2.97665179e-01 -1.30188093e-01\n",
            "  -6.41325116e-02 -7.50524104e-02 -1.54082611e-01  1.42427683e-02\n",
            "   2.82664001e-01 -1.53647617e-01 -1.91577196e-01 -2.36812904e-01\n",
            "  -2.64187455e-02 -1.23768240e-01 -9.71703380e-02 -1.42755151e-01]\n",
            " [ 3.81006718e-01  9.74208474e-01  2.51536965e-01 -1.06086075e-01\n",
            "   2.47642994e-02 -2.14334786e-01  1.11618765e-01 -3.31251144e-01\n",
            "   3.03457439e-01 -5.22540212e-02 -1.92027837e-01  7.85291791e-02\n",
            "  -8.42834711e-02  2.98029423e-01 -1.63834989e-02 -7.28954673e-02\n",
            "  -1.34878069e-01 -7.51429200e-02  1.52602613e-01  6.55063391e-02]\n",
            " [ 3.89671206e-01  9.45438147e-01  2.74852514e-01 -1.93518817e-01\n",
            "   1.23492301e-01 -2.15010211e-01  8.21060017e-02  1.35221392e-01\n",
            "   1.26983225e-01  3.30506980e-01 -1.31856784e-01  3.67536419e-03\n",
            "   3.46166193e-02 -2.68371016e-01  2.19020128e-01  2.50614941e-01\n",
            "   2.49089062e-01  1.58114731e-02 -1.31150424e-01  1.43262178e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O809xCPIjt7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a7e8a8ff-fa49-475c-8b91-7e06ea8d1047"
      },
      "source": [
        "print(model.layers[0].get_weights()[1])  # 첫번째 Layer의 bias 를 가져오는 방법이다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-6.4430618e-01 -8.1603396e-01  0.0000000e+00  1.2230252e-07\n",
            " -7.1575880e-07 -7.5524014e-28 -2.2723086e-02  0.0000000e+00\n",
            "  0.0000000e+00  0.0000000e+00 -4.8475772e-02 -5.6603275e-02\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "  0.0000000e+00 -1.1057972e-18  0.0000000e+00 -2.8524427e-15]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}