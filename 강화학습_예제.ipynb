{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "강화학습 예제",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNczzuk2GsSBMsSuUHW88g/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjbaek12/sjbaek12.github.io/blob/master/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5_%EC%98%88%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4vqY6BwzMBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oo2ymghzhAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "env = gym.make(\"CartPole-v0\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keKQ6vi-zftl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72064bba-01bb-40b6-9bbc-eebdd96c72ca"
      },
      "source": [
        "# Try running environment with random actions\n",
        "\n",
        "# CartPole은 막대기를 쓰러뜨리지 않고 옮기는 것인데 매 에피소드마다 최대보상이 200이고, \n",
        "# 매번 step마다 1의 보상을 얻는데 100에피소드를 해서 모두 195점 이상 얻으면 학습이 완료된 것으로 인정한다.\n",
        "\n",
        "env.reset()  # 새로운 에피소드를 불러온다.\n",
        "reward_sum = 0\n",
        "num_games = 10\n",
        "num_game = 0\n",
        "while num_game < num_games:\n",
        "#     env.render()  # 행동을 하기전 환경에 대해 얻은 관찰값을 그린다.\n",
        "    observation, reward, done, _ = env.step(env.action_space.sample())\n",
        "    # env.action_space.sample() 환경에서 행동 샘플링이다. 1은 오른쪽 이동 , 0은 왼쪽 이동이다.\n",
        "    # env.step 행동을 취한 후 환경에서 얻은 관찰값으로 제어\n",
        "    # observation은 4개의 실수로 구성된 배열로 state를 나타낸다\n",
        "    # done은 episode가 종료되었을때 True 이다. 막대기가 쓰러지면 종료된다.\n",
        "    print(observation, reward, done)\n",
        "    reward_sum += reward\n",
        "    if done:\n",
        "        print(\"Reward for this episode was: {}\".format(reward_sum))\n",
        "        reward_sum = 0\n",
        "        num_game += 1\n",
        "        env.reset()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.02733558 -0.19326005  0.04402046  0.35086633] 1.0 False\n",
            "[0.02347038 0.00120913 0.05103778 0.07238298] 1.0 False\n",
            "[ 0.02349456  0.19556364  0.05248544 -0.20377058] 1.0 False\n",
            "[ 0.02740583  0.38989724  0.04841003 -0.47944594] 1.0 False\n",
            "[ 0.03520378  0.58430355  0.03882111 -0.75648678] 1.0 False\n",
            "[ 0.04688985  0.77886953  0.02369138 -1.03670532] 1.0 False\n",
            "[ 0.06246724  0.5834408   0.00295727 -0.73667987] 1.0 False\n",
            "[ 0.07413606  0.38827813 -0.01177633 -0.44306771] 1.0 False\n",
            "[ 0.08190162  0.19332478 -0.02063768 -0.15412012] 1.0 False\n",
            "[ 0.08576811  0.38873605 -0.02372008 -0.45324166] 1.0 False\n",
            "[ 0.09354284  0.58418526 -0.03278492 -0.75330604] 1.0 False\n",
            "[ 0.10522654  0.38953031 -0.04785104 -0.47111757] 1.0 False\n",
            "[ 0.11301715  0.58529434 -0.05727339 -0.77849032] 1.0 False\n",
            "[ 0.12472303  0.39100471 -0.0728432  -0.50436292] 1.0 False\n",
            "[ 0.13254313  0.19698088 -0.08293045 -0.23549593] 1.0 False\n",
            "[ 0.13648275  0.39318374 -0.08764037 -0.55314238] 1.0 False\n",
            "[ 0.14434642  0.19939476 -0.09870322 -0.28930784] 1.0 False\n",
            "[ 0.14833432  0.00580869 -0.10448938 -0.02931372] 1.0 False\n",
            "[ 0.14845049  0.20226183 -0.10507565 -0.35305023] 1.0 False\n",
            "[ 0.15249573  0.00877873 -0.11213666 -0.09526171] 1.0 False\n",
            "[ 0.1526713   0.20531437 -0.11404189 -0.42111272] 1.0 False\n",
            "[ 0.15677759  0.0119773  -0.12246414 -0.1664466 ] 1.0 False\n",
            "[ 0.15701713  0.20862004 -0.12579308 -0.49511615] 1.0 False\n",
            "[ 0.16118954  0.01547563 -0.1356954  -0.24457443] 1.0 False\n",
            "[ 0.16149905  0.21224846 -0.14058689 -0.57679256] 1.0 False\n",
            "[ 0.16574402  0.01934793 -0.15212274 -0.33149304] 1.0 False\n",
            "[ 0.16613098 -0.17331838 -0.1587526  -0.09038284] 1.0 False\n",
            "[ 0.16266461  0.02368075 -0.16056026 -0.42864319] 1.0 False\n",
            "[ 0.16313822  0.22066895 -0.16913312 -0.7673271 ] 1.0 False\n",
            "[ 0.1675516   0.41766541 -0.18447966 -1.1080938 ] 1.0 False\n",
            "[ 0.17590491  0.22538322 -0.20664154 -0.87849443] 1.0 False\n",
            "[ 0.18041257  0.03357748 -0.22421143 -0.65722786] 1.0 True\n",
            "Reward for this episode was: 32.0\n",
            "[ 0.03874358 -0.16804184 -0.02160591  0.31126341] 1.0 False\n",
            "[ 0.03538274  0.02738116 -0.01538064  0.01184568] 1.0 False\n",
            "[ 0.03593036 -0.16751688 -0.01514373  0.29963643] 1.0 False\n",
            "[ 0.03258003 -0.36241974 -0.009151    0.5875051 ] 1.0 False\n",
            "[ 0.02533163 -0.16717083  0.0025991   0.29195365] 1.0 False\n",
            "[ 0.02198821 -0.36232974  0.00843818  0.58545517] 1.0 False\n",
            "[ 0.01474162 -0.55756887  0.02014728  0.88078422] 1.0 False\n",
            "[ 0.00359024 -0.36272632  0.03776297  0.59450261] 1.0 False\n",
            "[-0.00366428 -0.1681527   0.04965302  0.31394994] 1.0 False\n",
            "[-0.00702734  0.02622806  0.05593202  0.03733014] 1.0 False\n",
            "[-0.00650278 -0.1696495   0.05667862  0.34712246] 1.0 False\n",
            "[-0.00989577  0.02462238  0.06362107  0.07283717] 1.0 False\n",
            "[-0.00940332  0.21877727  0.06507781 -0.19911399] 1.0 False\n",
            "[-0.00502777  0.41291099  0.06109553 -0.47057877] 1.0 False\n",
            "[ 0.00323045  0.21698165  0.05168396 -0.15928218] 1.0 False\n",
            "[0.00757008 0.02115932 0.04849831 0.14924741] 1.0 False\n",
            "[ 0.00799326  0.21555444  0.05148326 -0.12774951] 1.0 False\n",
            "[ 0.01230435  0.40990251  0.04892827 -0.40375596] 1.0 False\n",
            "[ 0.0205024   0.21412203  0.04085315 -0.09605751] 1.0 False\n",
            "[ 0.02478484  0.40863536  0.038932   -0.37557658] 1.0 False\n",
            "[ 0.03295755  0.60318333  0.03142047 -0.65573428] 1.0 False\n",
            "[ 0.04502122  0.79785408  0.01830578 -0.93836018] 1.0 False\n",
            "[ 6.09782996e-02  9.92724504e-01 -4.61418603e-04 -1.22523524e+00] 1.0 False\n",
            "[ 0.08083279  0.7976085  -0.02496612 -0.93269692] 1.0 False\n",
            "[ 0.09678496  0.99305825 -0.04362006 -1.23311947] 1.0 False\n",
            "[ 0.11664612  0.79852346 -0.06828245 -0.95441507] 1.0 False\n",
            "[ 0.13261659  0.60438323 -0.08737075 -0.6839428 ] 1.0 False\n",
            "[ 0.14470426  0.41057609 -0.10104961 -0.41999531] 1.0 False\n",
            "[ 0.15291578  0.6069738  -0.10944951 -0.74274713] 1.0 False\n",
            "[ 0.16505526  0.80342261 -0.12430446 -1.06777109] 1.0 False\n",
            "[ 0.18112371  0.61014455 -0.14565988 -0.81654242] 1.0 False\n",
            "[ 0.1933266   0.8069283  -0.16199073 -1.15126497] 1.0 False\n",
            "[ 0.20946517  0.61424729 -0.18501603 -0.91344453] 1.0 False\n",
            "[ 0.22175011  0.81132474 -0.20328492 -1.25810042] 1.0 False\n",
            "[ 0.23797661  0.61929946 -0.22844693 -1.03534857] 1.0 True\n",
            "Reward for this episode was: 35.0\n",
            "[-0.00774963 -0.21136684 -0.03592096  0.25858681] 1.0 False\n",
            "[-0.01197696 -0.40595805 -0.03074922  0.53972684] 1.0 False\n",
            "[-0.02009613 -0.60063457 -0.01995469  0.82256472] 1.0 False\n",
            "[-0.03210882 -0.40524538 -0.00350339  0.523673  ] 1.0 False\n",
            "[-0.04021372 -0.2100743   0.00697007  0.22988818] 1.0 False\n",
            "[-0.04441521 -0.40529515  0.01156783  0.52476153] 1.0 False\n",
            "[-0.05252111 -0.60057797  0.02206306  0.82106702] 1.0 False\n",
            "[-0.06453267 -0.40576476  0.0384844   0.53540434] 1.0 False\n",
            "[-0.07264797 -0.2112045   0.04919249  0.25509166] 1.0 False\n",
            "[-0.07687206 -0.40699304  0.05429432  0.56287597] 1.0 False\n",
            "[-0.08501192 -0.21267332  0.06555184  0.28778059] 1.0 False\n",
            "[-0.08926538 -0.40866586  0.07130745  0.60039643] 1.0 False\n",
            "[-0.0974387  -0.21461012  0.08331538  0.33099918] 1.0 False\n",
            "[-0.1017309  -0.02076685  0.08993537  0.06570924] 1.0 False\n",
            "[-0.10214624  0.17295828  0.09124955 -0.19729868] 1.0 False\n",
            "[-0.09868708  0.3666646   0.08730358 -0.45985918] 1.0 False\n",
            "[-0.09135378  0.1704241   0.07810639 -0.14098485] 1.0 False\n",
            "[-0.0879453   0.36434556  0.0752867  -0.40804028] 1.0 False\n",
            "[-0.08065839  0.16824136  0.06712589 -0.09260385] 1.0 False\n",
            "[-0.07729356  0.36234018  0.06527381 -0.36337619] 1.0 False\n",
            "[-0.07004676  0.55647663  0.05800629 -0.63478385] 1.0 False\n",
            "[-0.05891723  0.75074357  0.04531061 -0.90864986] 1.0 False\n",
            "[-0.04390236  0.94522388  0.02713762 -1.18675416] 1.0 False\n",
            "[-0.02499788  0.74976074  0.00340253 -0.88568992] 1.0 False\n",
            "[-0.01000266  0.94483633 -0.01431127 -1.17730128] 1.0 False\n",
            "[ 0.00889406  0.74990317 -0.03785729 -0.88913884] 1.0 False\n",
            "[ 0.02389213  0.94551783 -0.05564007 -1.19347799] 1.0 False\n",
            "[ 0.04280248  1.14131451 -0.07950963 -1.50306825] 1.0 False\n",
            "[ 0.06562877  0.94724256 -0.10957099 -1.23623122] 1.0 False\n",
            "[ 0.08457362  1.14358854 -0.13429562 -1.56113343] 1.0 False\n",
            "[ 0.1074454   0.95030469 -0.16551829 -1.31318252] 1.0 False\n",
            "[ 0.12645149  1.14708922 -0.19178194 -1.65276564] 1.0 False\n",
            "[ 0.14939327  0.95465435 -0.22483725 -1.42544434] 1.0 True\n",
            "Reward for this episode was: 33.0\n",
            "[ 0.00177931 -0.20208876  0.03198194  0.28574226] 1.0 False\n",
            "[-0.00226247 -0.39765189  0.03769679  0.58833803] 1.0 False\n",
            "[-0.0102155  -0.20307755  0.04946355  0.3077641 ] 1.0 False\n",
            "[-0.01427706 -0.39886813  0.05561883  0.61562713] 1.0 False\n",
            "[-0.02225442 -0.59472125  0.06793137  0.92529604] 1.0 False\n",
            "[-0.03414884 -0.4005793   0.08643729  0.65471124] 1.0 False\n",
            "[-0.04216043 -0.20676041  0.09953152  0.39044924] 1.0 False\n",
            "[-0.04629564 -0.01318156  0.1073405   0.13073201] 1.0 False\n",
            "[-0.04655927  0.18025211  0.10995514 -0.12625099] 1.0 False\n",
            "[-0.04295423 -0.01625923  0.10743012  0.19899764] 1.0 False\n",
            "[-0.04327941 -0.21274063  0.11141008  0.52354439] 1.0 False\n",
            "[-0.04753422 -0.01934846  0.12188096  0.26794143] 1.0 False\n",
            "[-0.04792119  0.17384236  0.12723979  0.01604926] 1.0 False\n",
            "[-0.04444435  0.36693167  0.12756078 -0.23393563] 1.0 False\n",
            "[-0.03710571  0.1702398   0.12288206  0.09610628] 1.0 False\n",
            "[-0.03370092 -0.02640949  0.12480419  0.42489244] 1.0 False\n",
            "[-0.03422911 -0.2230579   0.13330204  0.75416803] 1.0 False\n",
            "[-0.03869026 -0.03000091  0.1483854   0.50622645] 1.0 False\n",
            "[-0.03929028 -0.22686801  0.15850993  0.84174746] 1.0 False\n",
            "[-0.04382764 -0.42375728  0.17534488  1.17978595] 1.0 False\n",
            "[-0.05230279 -0.23129048  0.1989406   0.94680019] 1.0 False\n",
            "[-0.0569286  -0.03932273  0.2178766   0.72263147] 1.0 True\n",
            "Reward for this episode was: 22.0\n",
            "[ 0.01943962  0.20507117 -0.00150783 -0.26332807] 1.0 False\n",
            "[ 0.02354105  0.00997077 -0.00677439  0.02887889] 1.0 False\n",
            "[ 0.02374046  0.20518921 -0.00619681 -0.26593371] 1.0 False\n",
            "[ 0.02784425  0.01015625 -0.01151548  0.02478827] 1.0 False\n",
            "[ 0.02804737 -0.18479868 -0.01101972  0.3138158 ] 1.0 False\n",
            "[ 0.0243514  -0.37976193 -0.0047434   0.60300319] 1.0 False\n",
            "[ 0.01675616 -0.18457396  0.00731666  0.30882997] 1.0 False\n",
            "[0.01306468 0.01044298 0.01349326 0.01846347] 1.0 False\n",
            "[ 0.01327354 -0.18486985  0.01386253  0.31537295] 1.0 False\n",
            "[ 0.00957614 -0.38018649  0.02016999  0.61239521] 1.0 False\n",
            "[ 0.00197241 -0.18535215  0.03241789  0.32613272] 1.0 False\n",
            "[-0.00173463  0.00929361  0.03894055  0.04384668] 1.0 False\n",
            "[-0.00154876 -0.18636447  0.03981748  0.34855694] 1.0 False\n",
            "[-0.00527605 -0.38202946  0.04678862  0.65352503] 1.0 False\n",
            "[-0.01291664 -0.18758918  0.05985912  0.37593464] 1.0 False\n",
            "[-0.01666842 -0.383508    0.06737781  0.68687459] 1.0 False\n",
            "[-0.02433858 -0.57949733  0.0811153   0.99998562] 1.0 False\n",
            "[-0.03592853 -0.38554772  0.10111502  0.73383953] 1.0 False\n",
            "[-0.04363948 -0.5819105   0.11579181  1.05655644] 1.0 False\n",
            "[-0.05527769 -0.38849745  0.13692294  0.80234638] 1.0 False\n",
            "[-0.06304764 -0.58520474  0.15296986  1.13477542] 1.0 False\n",
            "[-0.07475173 -0.78196075  0.17566537  1.47126108] 1.0 False\n",
            "[-0.09039095 -0.58936792  0.20509059  1.23819812] 1.0 False\n",
            "[-0.10217831 -0.3973835   0.22985456  1.01613157] 1.0 True\n",
            "Reward for this episode was: 24.0\n",
            "[-0.04895462  0.23785675  0.04112118 -0.24033104] 1.0 False\n",
            "[-0.04419749  0.43236789  0.03631456 -0.51976488] 1.0 False\n",
            "[-0.03555013  0.23675403  0.02591927 -0.21586341] 1.0 False\n",
            "[-0.03081505  0.43149603  0.021602   -0.50025889] 1.0 False\n",
            "[-0.02218513  0.23607632  0.01159682 -0.20084721] 1.0 False\n",
            "[-0.0174636   0.43103051  0.00757988 -0.48984945] 1.0 False\n",
            "[-0.00884299  0.62604471 -0.00221711 -0.78013389] 1.0 False\n",
            "[ 0.0036779   0.43095331 -0.01781979 -0.48814933] 1.0 False\n",
            "[ 0.01229697  0.62632209 -0.02758278 -0.78639471] 1.0 False\n",
            "[ 0.02482341  0.43158971 -0.04331067 -0.50251557] 1.0 False\n",
            "[ 0.0334552   0.62729451 -0.05336098 -0.80852684] 1.0 False\n",
            "[ 0.04600109  0.43294282 -0.06953152 -0.53309494] 1.0 False\n",
            "[ 0.05465995  0.23886413 -0.08019342 -0.26310613] 1.0 False\n",
            "[ 0.05943723  0.43503372 -0.08545554 -0.57996646] 1.0 False\n",
            "[ 0.06813791  0.24120668 -0.09705487 -0.3153802 ] 1.0 False\n",
            "[ 0.07296204  0.4375675  -0.10336247 -0.63702464] 1.0 False\n",
            "[ 0.08171339  0.24402729 -0.11610297 -0.37859824] 1.0 False\n",
            "[ 0.08659394  0.4405902  -0.12367493 -0.70551523] 1.0 False\n",
            "[ 0.09540574  0.63718898 -0.13778524 -1.03442879] 1.0 False\n",
            "[ 0.10814952  0.83384722 -0.15847381 -1.36700124] 1.0 False\n",
            "[ 0.12482646  0.64102382 -0.18581384 -1.127787  ] 1.0 False\n",
            "[ 0.13764694  0.83802845 -0.20836958 -1.47252259] 1.0 False\n",
            "[ 0.15440751  1.03499861 -0.23782003 -1.82240531] 1.0 True\n",
            "Reward for this episode was: 23.0\n",
            "[-0.03343808 -0.15113159 -0.04229993  0.30787689] 1.0 False\n",
            "[-0.03646071  0.04456677 -0.0361424   0.00215947] 1.0 False\n",
            "[-0.03556938 -0.15001871 -0.03609921  0.28322352] 1.0 False\n",
            "[-0.03856975  0.04559904 -0.03043474 -0.02062279] 1.0 False\n",
            "[-0.03765777 -0.14907353 -0.03084719  0.26230439] 1.0 False\n",
            "[-0.04063924 -0.34374188 -0.02560111  0.54510038] 1.0 False\n",
            "[-0.04751408 -0.14826973 -0.0146991   0.24446232] 1.0 False\n",
            "[-0.05047947 -0.34317868 -0.00980985  0.53247279] 1.0 False\n",
            "[-0.05734305 -0.53816129  0.0008396   0.82204858] 1.0 False\n",
            "[-0.06810627 -0.73329472  0.01728058  1.11499547] 1.0 False\n",
            "[-0.08277217 -0.53840385  0.03958049  0.82778304] 1.0 False\n",
            "[-0.09354024 -0.34384479  0.05613615  0.54780664] 1.0 False\n",
            "[-0.10041714 -0.53970858  0.06709228  0.8576349 ] 1.0 False\n",
            "[-0.11121131 -0.73567729  0.08424498  1.17063695] 1.0 False\n",
            "[-0.12592486 -0.5417458   0.10765772  0.90551012] 1.0 False\n",
            "[-0.13675977 -0.73814794  0.12576792  1.229998  ] 1.0 False\n",
            "[-0.15152273 -0.54484813  0.15036788  0.97921677] 1.0 False\n",
            "[-0.1624197  -0.74163096  0.16995221  1.31510204] 1.0 False\n",
            "[-0.17725231 -0.93844626  0.19625425  1.65579743] 1.0 False\n",
            "[-0.19602124 -0.7460808   0.2293702   1.43011732] 1.0 True\n",
            "Reward for this episode was: 20.0\n",
            "[-0.01520039 -0.15866003 -0.0336646   0.3095569 ] 1.0 False\n",
            "[-0.01837359  0.036925   -0.02747347  0.00645007] 1.0 False\n",
            "[-0.01763509 -0.15779239 -0.02734446  0.29033975] 1.0 False\n",
            "[-0.02079094  0.03770858 -0.02153767 -0.01084036] 1.0 False\n",
            "[-0.02003677 -0.15709797 -0.02175448  0.27497012] 1.0 False\n",
            "[-0.02317873  0.0383275  -0.01625507 -0.02449404] 1.0 False\n",
            "[-0.02241218 -0.15655761 -0.01674496  0.26301623] 1.0 False\n",
            "[-0.02554333 -0.3514366  -0.01148463  0.55037093] 1.0 False\n",
            "[-0.03257206 -0.15615523 -0.00047721  0.2540918 ] 1.0 False\n",
            "[-0.03569517  0.03897353  0.00460462 -0.03874161] 1.0 False\n",
            "[-0.0349157  -0.15621415  0.00382979  0.25539055] 1.0 False\n",
            "[-0.03803998  0.03885291  0.0089376  -0.03608194] 1.0 False\n",
            "[-0.03726292 -0.15639606  0.00821596  0.25940744] 1.0 False\n",
            "[-0.04039084 -0.35163433  0.01340411  0.55467043] 1.0 False\n",
            "[-0.04742353 -0.15670313  0.02449752  0.26624059] 1.0 False\n",
            "[-0.05055759 -0.35216599  0.02982233  0.56654847] 1.0 False\n",
            "[-0.05760091 -0.15747481  0.0411533   0.28340802] 1.0 False\n",
            "[-0.06075041  0.03703674  0.04682146  0.00398338] 1.0 False\n",
            "[-0.06000967  0.23145702  0.04690113 -0.27356696] 1.0 False\n",
            "[-0.05538053  0.03569833  0.04142979  0.03353205] 1.0 False\n",
            "[-0.05466657  0.23020243  0.04210043 -0.24579687] 1.0 False\n",
            "[-0.05006252  0.42469859  0.03718449 -0.52490872] 1.0 False\n",
            "[-0.04156855  0.22907362  0.02668632 -0.22074439] 1.0 False\n",
            "[-0.03698707  0.42380416  0.02227143 -0.50489134] 1.0 False\n",
            "[-0.02851099  0.22837554  0.01217361 -0.20527385] 1.0 False\n",
            "[-0.02394348  0.03308163  0.00806813  0.09122425] 1.0 False\n",
            "[-0.02328185  0.22808702  0.00989261 -0.1989023 ] 1.0 False\n",
            "[-0.01872011  0.42306609  0.00591457 -0.48844822] 1.0 False\n",
            "[-0.01025878  0.6181041  -0.0038544  -0.77926124] 1.0 False\n",
            "[ 0.0021033   0.42303535 -0.01943962 -0.48779348] 1.0 False\n",
            "[ 0.010564    0.228193   -0.02919549 -0.20130006] 1.0 False\n",
            "[ 0.01512786  0.42372007 -0.03322149 -0.50304794] 1.0 False\n",
            "[ 0.02360227  0.61929413 -0.04328245 -0.80601248] 1.0 False\n",
            "[ 0.03598815  0.42479136 -0.0594027  -0.52725263] 1.0 False\n",
            "[ 0.04448398  0.6206966  -0.06994775 -0.83804631] 1.0 False\n",
            "[ 0.05689791  0.42659602 -0.08670868 -0.56815528] 1.0 False\n",
            "[ 0.06542983  0.23279045 -0.09807178 -0.30399949] 1.0 False\n",
            "[ 0.07008564  0.03919298 -0.10415177 -0.04378559] 1.0 False\n",
            "[ 0.0708695  -0.15429324 -0.10502749  0.21430572] 1.0 False\n",
            "[ 0.06778363 -0.3477691  -0.10074137  0.472099  ] 1.0 False\n",
            "[ 0.06082825 -0.15137934 -0.09129939  0.14944005] 1.0 False\n",
            "[ 0.05780066  0.04492333 -0.08831059 -0.17059233] 1.0 False\n",
            "[ 0.05869913 -0.14883092 -0.09172244  0.09297692] 1.0 False\n",
            "[ 0.05572251  0.04747782 -0.0898629  -0.227177  ] 1.0 False\n",
            "[ 0.05667207 -0.14625265 -0.09440644  0.03586201] 1.0 False\n",
            "[ 0.05374701  0.05008742 -0.0936892  -0.28505093] 1.0 False\n",
            "[ 0.05474876 -0.14358213 -0.09939022 -0.02332499] 1.0 False\n",
            "[ 0.05187712 -0.33714865 -0.09985672  0.23641924] 1.0 False\n",
            "[ 0.04513415 -0.53071269 -0.09512833  0.49600981] 1.0 False\n",
            "[ 0.03451989 -0.72437353 -0.08520814  0.75726211] 1.0 False\n",
            "[ 0.02003242 -0.91822426 -0.07006289  1.02196237] 1.0 False\n",
            "[ 0.00166794 -0.7222424  -0.04962365  0.70812917] 1.0 False\n",
            "[-0.01277691 -0.52646945 -0.03546106  0.40024788] 1.0 False\n",
            "[-0.0233063  -0.33086289 -0.02745611  0.09659914] 1.0 False\n",
            "[-0.02992356 -0.52558079 -0.02552412  0.38049482] 1.0 False\n",
            "[-0.04043517 -0.33010587 -0.01791423  0.07987467] 1.0 False\n",
            "[-0.04703729 -0.5249665  -0.01631673  0.3668522 ] 1.0 False\n",
            "[-0.05753662 -0.71985283 -0.00897969  0.65434588] 1.0 False\n",
            "[-0.07193368 -0.524607    0.00410723  0.35884896] 1.0 False\n",
            "[-0.08242582 -0.32954368  0.01128421  0.06746397] 1.0 False\n",
            "[-0.08901669 -0.52482558  0.01263349  0.36368566] 1.0 False\n",
            "[-0.0995132  -0.72012479  0.0199072   0.66032523] 1.0 False\n",
            "[-0.1139157  -0.52528544  0.0331137   0.37397645] 1.0 False\n",
            "[-0.12442141 -0.72086174  0.04059323  0.67691372] 1.0 False\n",
            "[-0.13883864 -0.52632661  0.05413151  0.39728256] 1.0 False\n",
            "[-0.14936517 -0.72217309  0.06207716  0.70652887] 1.0 False\n",
            "[-0.16380864 -0.52796361  0.07620774  0.43401473] 1.0 False\n",
            "[-0.17436791 -0.33399864  0.08488803  0.16629511] 1.0 False\n",
            "[-0.18104788 -0.53022667  0.08821393  0.4845044 ] 1.0 False\n",
            "[-0.19165241 -0.33645315  0.09790402  0.22087558] 1.0 False\n",
            "[-0.19838148 -0.14285702  0.10232153 -0.03939016] 1.0 False\n",
            "[-0.20123862  0.05066013  0.10153373 -0.2981176 ] 1.0 False\n",
            "[-0.20022541 -0.14575154  0.09557138  0.02478224] 1.0 False\n",
            "[-0.20314045 -0.3421049   0.09606702  0.34602344] 1.0 False\n",
            "[-0.20998254 -0.53845275  0.10298749  0.66738748] 1.0 False\n",
            "[-0.2207516  -0.73484472  0.11633524  0.99063938] 1.0 False\n",
            "[-0.23544849 -0.93131526  0.13614803  1.31747864] 1.0 False\n",
            "[-0.2540748  -0.73815236  0.1624976   1.07031952] 1.0 False\n",
            "[-0.26883785 -0.93500613  0.18390399  1.40927456] 1.0 False\n",
            "[-0.28753797 -1.13187043  0.21208948  1.75335502] 1.0 True\n",
            "Reward for this episode was: 80.0\n",
            "[-0.01870432 -0.17835871  0.04736013  0.30349737] 1.0 False\n",
            "[-0.02227149  0.01605742  0.05343008  0.02611885] 1.0 False\n",
            "[-0.02195034  0.21037404  0.05395246 -0.24923917] 1.0 False\n",
            "[-0.01774286  0.01452478  0.04896767  0.05996159] 1.0 False\n",
            "[-0.01745237  0.20891168  0.05016691 -0.2168785 ] 1.0 False\n",
            "[-0.01327413  0.4032819   0.04582934 -0.49332416] 1.0 False\n",
            "[-0.00520849  0.20754455  0.03596285 -0.1865573 ] 1.0 False\n",
            "[-0.0010576   0.402134    0.03223171 -0.46768194] 1.0 False\n",
            "[ 0.00698508  0.59678611  0.02287807 -0.75003397] 1.0 False\n",
            "[ 0.0189208   0.4013562   0.00787739 -0.45024026] 1.0 False\n",
            "[ 0.02694792  0.59636586 -0.00112742 -0.74042974] 1.0 False\n",
            "[ 0.03887524  0.79150336 -0.01593601 -1.03346727] 1.0 False\n",
            "[ 0.05470531  0.59659693 -0.03660536 -0.74582974] 1.0 False\n",
            "[ 0.06663725  0.4019987  -0.05152195 -0.4648875 ] 1.0 False\n",
            "[ 0.07467722  0.59780938 -0.0608197  -0.77335453] 1.0 False\n",
            "[ 0.08663341  0.793713   -0.07628679 -1.08453661] 1.0 False\n",
            "[ 0.10250767  0.59967589 -0.09797753 -0.81673402] 1.0 False\n",
            "[ 0.11450119  0.40602203 -0.11431221 -0.5564057 ] 1.0 False\n",
            "[ 0.12262163  0.21267485 -0.12544032 -0.3018124 ] 1.0 False\n",
            "[ 0.12687512  0.40934062 -0.13147657 -0.63127597] 1.0 False\n",
            "[ 0.13506194  0.21627441 -0.14410209 -0.3827189 ] 1.0 False\n",
            "[ 0.13938742  0.02346102 -0.15175646 -0.13871606] 1.0 False\n",
            "[ 0.13985664  0.22039396 -0.15453079 -0.47516582] 1.0 False\n",
            "[ 0.14426452  0.41732173 -0.1640341  -0.81228899] 1.0 False\n",
            "[ 0.15261096  0.22478087 -0.18027988 -0.57536459] 1.0 False\n",
            "[ 0.15710658  0.42191099 -0.19178717 -0.91898325] 1.0 False\n",
            "[ 0.1655448   0.22982621 -0.21016684 -0.69217925] 1.0 True\n",
            "Reward for this episode was: 27.0\n",
            "[-0.01245606 -0.21251841  0.01082366  0.30750823] 1.0 False\n",
            "[-0.01670643 -0.01755235  0.01697383  0.01825836] 1.0 False\n",
            "[-0.01705748  0.17732212  0.01733899 -0.26902116] 1.0 False\n",
            "[-0.01351104  0.37219239  0.01195857 -0.55618522] 1.0 False\n",
            "[-0.00606719  0.17690461  0.00083487 -0.25975875] 1.0 False\n",
            "[-0.0025291  -0.01822925 -0.00436031  0.03318738] 1.0 False\n",
            "[-0.00289368  0.17695496 -0.00369656 -0.26086807] 1.0 False\n",
            "[ 0.00064542 -0.01811403 -0.00891392  0.03064663] 1.0 False\n",
            "[ 2.83136024e-04 -2.13107026e-01 -8.30098994e-03  3.20503838e-01] 1.0 False\n",
            "[-0.003979   -0.40810978 -0.00189091  0.61055743] 1.0 False\n",
            "[-0.0121412  -0.21296145  0.01032024  0.31727953] 1.0 False\n",
            "[-0.01640043 -0.017988    0.01666583  0.02786903] 1.0 False\n",
            "[-0.01676019 -0.21334494  0.01722321  0.32576327] 1.0 False\n",
            "[-0.02102709 -0.40870783  0.02373847  0.6238275 ] 1.0 False\n",
            "[-0.02920124 -0.60415302  0.03621502  0.92389116] 1.0 False\n",
            "[-0.04128431 -0.40953851  0.05469285  0.64280569] 1.0 False\n",
            "[-0.04947508 -0.21521983  0.06754896  0.36783518] 1.0 False\n",
            "[-0.05377947 -0.02111948  0.07490566  0.09719294] 1.0 False\n",
            "[-0.05420186 -0.21723062  0.07684952  0.41253645] 1.0 False\n",
            "[-0.05854647 -0.02327737  0.08510025  0.14503678] 1.0 False\n",
            "[-0.05901202  0.1705293   0.08800099 -0.1196319 ] 1.0 False\n",
            "[-0.05560144  0.36428741  0.08560835 -0.38330551] 1.0 False\n",
            "[-0.04831569  0.16806092  0.07794224 -0.06490558] 1.0 False\n",
            "[-0.04495447  0.36198388  0.07664413 -0.33201509] 1.0 False\n",
            "[-0.03771479  0.55593598  0.07000382 -0.59957783] 1.0 False\n",
            "[-0.02659607  0.7500123   0.05801227 -0.86941498] 1.0 False\n",
            "[-0.01159583  0.55415117  0.04062397 -0.55907146] 1.0 False\n",
            "[-0.0005128   0.35848325  0.02944254 -0.25387158] 1.0 False\n",
            "[ 0.00665686  0.5531727   0.02436511 -0.53712433] 1.0 False\n",
            "[ 0.01772032  0.35771681  0.01362262 -0.23686487] 1.0 False\n",
            "[ 0.02487465  0.55264151  0.00888532 -0.52521987] 1.0 False\n",
            "[ 0.03592748  0.35739566 -0.00161907 -0.2297504 ] 1.0 False\n",
            "[ 0.0430754   0.55254071 -0.00621408 -0.5229436 ] 1.0 False\n",
            "[ 0.05412621  0.35750677 -0.01667295 -0.23222527] 1.0 False\n",
            "[ 0.06127635  0.16262697 -0.02131746  0.05515217] 1.0 False\n",
            "[ 0.06452889  0.35804799 -0.02021442 -0.24417962] 1.0 False\n",
            "[ 0.07168985  0.16322052 -0.02509801  0.04205926] 1.0 False\n",
            "[ 0.07495426 -0.03153271 -0.02425682  0.32671906] 1.0 False\n",
            "[ 0.0743236  -0.22630106 -0.01772244  0.61165484] 1.0 False\n",
            "[ 0.06979758 -0.42117089 -0.00548935  0.89870355] 1.0 False\n",
            "[ 0.06137416 -0.61621802  0.01248473  1.18965597] 1.0 False\n",
            "[ 0.0490498  -0.81149953  0.03627785  1.48622583] 1.0 False\n",
            "[ 0.03281981 -0.61683798  0.06600236  1.20508897] 1.0 False\n",
            "[ 0.02048305 -0.42262822  0.09010414  0.93379924] 1.0 False\n",
            "[ 0.01203049 -0.61884262  0.10878013  1.25338167] 1.0 False\n",
            "[-3.46364932e-04 -8.15176641e-01  1.33847759e-01  1.57806031e+00] 1.0 False\n",
            "[-0.0166499  -1.01161513  0.16540897  1.9093164 ] 1.0 False\n",
            "[-0.0368822  -1.20809088  0.20359529  2.24841629] 1.0 False\n",
            "[-0.06104402 -1.40446802  0.24856362  2.59634237] 1.0 True\n",
            "Reward for this episode was: 49.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wKo0N2Fzc6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이과정은 성과가 좋은 행동을 mimicking하는 것이다.\n",
        "\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import keras.backend as K  # 케라스의 backend를 K. 형식으로 호출하는 것이고 여기서는 tensorflow이다.\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "def get_policy_model(env, hidden_layer_neurons, lr):\n",
        "    dimen = env.reset().shape # 환경의 shape이고 이것은 4개의 배열로 구성된다.\n",
        "    num_actions = env.action_space.n  # 가능한 액션의 숫자이다. 여기서는 2로 오른쪽이나 왼쪽으로 움직이는 것\n",
        "    \n",
        "    adv = layers.Input(shape=[1], name=\"advantages\")\n",
        "\n",
        "    # 네개 배열로 구성된 환경이 망으로 들어가서 2개의 가능한 액션을 산출하는 신경망이다.\n",
        "    inp = layers.Input(shape=dimen,name=\"input_x\")\n",
        "    x = layers.Dense(hidden_layer_neurons, \n",
        "                     activation=\"relu\", \n",
        "                     use_bias=False,\n",
        "                     kernel_initializer=glorot_uniform(seed=42),\n",
        "                     name=\"dense_1\")(inp)\n",
        "    out = layers.Dense(num_actions, \n",
        "                       activation=\"softmax\", \n",
        "                       kernel_initializer=glorot_uniform(seed=42),\n",
        "                       use_bias=False,\n",
        "                       name=\"out\")(x)\n",
        "\n",
        "    def custom_loss(y_true, y_pred):\n",
        "        # actual: 0 predict: 0 -> log(0 * (0 - 0) + (1 - 0) * (0 + 0)) = -inf\n",
        "        # actual: 1 predict: 1 -> log(1 * (1 - 1) + (1 - 1) * (1 + 1)) = -inf\n",
        "        # actual: 1 predict: 0 -> log(1 * (1 - 0) + (1 - 1) * (1 + 0)) = 0\n",
        "        # actual: 0 predict: 1 -> log(0 * (0 - 1) + (1 - 0) * (0 + 1)) = 0\n",
        "        log_lik = K.log(y_true * (y_true - y_pred) + (1 - y_true) * (y_true + y_pred))\n",
        "        return K.mean(log_lik * adv, keepdims=True)\n",
        "        \n",
        "    model_train = Model(inputs=[inp, adv], outputs=out)  # state가 input되고 action이 output이다. \n",
        "    model_train.compile(loss=custom_loss, optimizer=Adam(lr)) # 그러나 손실함수가 커스텀이다. output이 두개이므로 미분 가능한 형태로 하나로 합쳐서 만들어낸 것이다.\n",
        "    model_predict = Model(inputs=[inp], outputs=out)\n",
        "    return model_train, model_predict  # 이 함수의 산출물은 모델 자체와 예측값이다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFtxrB_Mzksd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discount_rewards(r, gamma=0.99):\n",
        "    \"\"\"Takes 1d float array of rewards and computes discounted reward\n",
        "    e.g. f([1, 1, 1], 0.99) -> [2.9701, 1.99, 1]\n",
        "    \"\"\"\n",
        "    prior = 0\n",
        "    out = []\n",
        "    for val in r:\n",
        "        new_val = val + prior * gamma\n",
        "        out.append(new_val)\n",
        "        prior = new_val\n",
        "    return np.array(out[::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KiANV6ozlet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Constants defining our neural network\n",
        "hidden_layer_neurons = 8\n",
        "gamma = .99\n",
        "dimen = len(env.reset())\n",
        "print_every = 100\n",
        "batch_size = 50\n",
        "num_episodes = 10000\n",
        "render = False\n",
        "lr = 1e-2\n",
        "goal = 100  # 않쓰러지는 목표 점수 같음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1q3gEZTCzoON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See our trained bot in action, 테스트 단계이다. 기존에 랜덤하게 만들어진 상황에 최상의 성과를 가져오는 액션을 산출하는 \n",
        "# 정책신경망에 random하게 만들어진 새로운 환경을 주입하고 그 것이 어떤 성과를 가져오는지 계산하는 것이다.\n",
        "def score_model(model, num_tests, render=False):\n",
        "    scores = []    \n",
        "    for num_test in range(num_tests):\n",
        "        observation = env.reset()\n",
        "        reward_sum = 0\n",
        "        while True:\n",
        "            if render:\n",
        "                env.render() # 행동을 하기전 환경에 대해 얻은 관찰값을 그린다\n",
        "\n",
        "            state = np.reshape(observation, [1, dimen]) # random하게 상태를 다시 만들어 내고\n",
        "            predict = model.predict([state])[0] # 그 상태에서 행동을 다시 예측한다.\n",
        "            action = np.argmax(predict) # 예측값중에서 몇번째가 최대값인지 알아낸다. 즉 random하게 한 행동 중에서 어떤 것이 최대의 성과를 냇는지 알아내는 것이다.\n",
        "            observation, reward, done, _ = env.step(action)\n",
        "            reward_sum += reward\n",
        "            if done:\n",
        "                break\n",
        "        scores.append(reward_sum)\n",
        "    env.close()\n",
        "    return np.mean(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHjhTC5Yzr4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "5e39faf2-954e-4049-b5b7-b31e8c2eb414"
      },
      "source": [
        "model_train, model_predict = get_policy_model(env, hidden_layer_neurons, lr)\n",
        "model_predict.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_x (InputLayer)         (None, 4)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "out (Dense)                  (None, 2)                 16        \n",
            "=================================================================\n",
            "Total params: 48\n",
            "Trainable params: 48\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z12SgHqpzuX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a1a79a91-7a9b-4b38-feaf-71cc8d006291"
      },
      "source": [
        "reward_sum = 0\n",
        "\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "# Placeholders for our observations, outputs and rewards\n",
        "states = np.empty(0).reshape(0,dimen)\n",
        "actions = np.empty(0).reshape(0,1)\n",
        "rewards = np.empty(0).reshape(0,1)\n",
        "discounted_rewards = np.empty(0).reshape(0,1)\n",
        "\n",
        "# Setting up our environment\n",
        "observation = env.reset() # 한개의 state를 발생시킨다.\n",
        "\n",
        "num_episode = 0\n",
        "\n",
        "losses = []\n",
        "\n",
        "while num_episode < num_episodes:\n",
        "    # Append the observations to our batch\n",
        "    state = np.reshape(observation, [1, dimen]) # 하나의 state를 (-1, 1, 4) array로 만든다.\n",
        "    \n",
        "    predict = model_predict.predict([state])[0]  # 한개의 state를 inout해서 신경망을 통해 action을 만들어낸다.\n",
        "    action = np.random.choice(range(num_actions),p=predict) # 대안 중에서 하나를 선택한다. p=[0.4, 0.6] 대안이 선택될 확율이다. action은 0 또는 1 이된다.\n",
        "    \n",
        "    # Append the observations and outputs for learning\n",
        "    states = np.vstack([states, state]) # 미리 만들어 놓은 placeholder인 states에 while문 밖에서 만들어낸 state를 append 시키다.\n",
        "    actions = np.vstack([actions, action]) # 동일하게 state가 입력이 되어서 신경망이 산출한 행동을 무작위로 선택한 행동을 actions에 append한다.\n",
        "    \n",
        "    # Determine the oucome of our action\n",
        "    observation, reward, done, _ = env.step(action)\n",
        "    reward_sum += reward\n",
        "    rewards = np.vstack([rewards, reward])\n",
        "    \n",
        "    if done:\n",
        "        # Determine standardized rewards\n",
        "        discounted_rewards_episode = discount_rewards(rewards, gamma)       \n",
        "        discounted_rewards = np.vstack([discounted_rewards, discounted_rewards_episode])\n",
        "        \n",
        "        rewards = np.empty(0).reshape(0,1)\n",
        "\n",
        "        if (num_episode + 1) % batch_size == 0:\n",
        "            discounted_rewards -= discounted_rewards.mean()\n",
        "            discounted_rewards /= discounted_rewards.std()\n",
        "            discounted_rewards = discounted_rewards.squeeze()\n",
        "            actions = actions.squeeze().astype(int)  # squeeze 함수는 배열에서 차원이 1인 것을 찾아서 없애버린다. 예) (2,2,1) --> (2,2)\n",
        "           \n",
        "            actions_train = np.zeros([len(actions), num_actions])\n",
        "            actions_train[np.arange(len(actions)), actions] = 1\n",
        "            \n",
        "            loss = model_train.train_on_batch([states, discounted_rewards], actions_train)  #####\n",
        "            losses.append(loss)\n",
        "\n",
        "            # Clear out game variables\n",
        "            states = np.empty(0).reshape(0,dimen)\n",
        "            actions = np.empty(0).reshape(0,1)\n",
        "            discounted_rewards = np.empty(0).reshape(0,1)\n",
        "\n",
        "\n",
        "        # Print periodically\n",
        "        if (num_episode + 1) % print_every == 0:\n",
        "            # Print status\n",
        "            score = score_model(model_predict,10)\n",
        "            print(\"Average reward for training episode {}: {:0.2f} Test Score: {:0.2f} Loss: {:0.6f} \".format(\n",
        "                (num_episode + 1), reward_sum/print_every, \n",
        "                score,\n",
        "                np.mean(losses[-print_every:])))\n",
        "            \n",
        "            if score >= goal:\n",
        "                print(\"Solved in {} episodes!\".format(num_episode))\n",
        "                break\n",
        "            reward_sum = 0\n",
        "                \n",
        "        num_episode += 1\n",
        "        observation = env.reset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average reward for training episode 100: 27.47 Test Score: 110.70 Loss: -0.003320 \n",
            "Solved in 99 episodes!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVfNxrViz5_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-3qNIaSz7ee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z1DOtulv19a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y= np.empty(0).reshape(0,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFNxRiUXxIyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99299ae1-a3a6-43e0-8eec-247654362328"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], shape=(0, 1), dtype=float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUBGIwJgQpPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85defa67-d424-4e8e-a595-7d058e6b5d4c"
      },
      "source": [
        "env.action_space.n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO0UtNSrQz3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observation = env.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C26VzC5nQ19v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bac1bee2-220f-4852-aeb0-32323210c2f9"
      },
      "source": [
        "observation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04977838,  0.04408428, -0.01042855,  0.003663  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snU79kciRDhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state = np.reshape(observation, [1, dimen])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpv8hfHrRPWZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdf14cae-2518-49c9-d165-a50a52ce9b38"
      },
      "source": [
        "dimen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtRY_2oRREli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b84e26e2-5df4-4abe-cced-b6f605cbcf5e"
      },
      "source": [
        "state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04977838,  0.04408428, -0.01042855,  0.003663  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOSyJwY0Rk59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " predict = model_predict.predict([state])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YyCkEXjRsHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b9d76d7-bcee-4da1-9c50-20b7db7c8c7a"
      },
      "source": [
        "predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4965743, 0.5034257], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLCjvRtuR-Nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a57b5ab-5769-4d05-c106-48d62fd6569b"
      },
      "source": [
        "#num_actions = env.action_space.n\n",
        "action = np.random.choice(range(num_actions),p=predict)\n",
        "print(action)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyZQTDCESG6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47c1a474-4696-4e1f-d3cd-5b8e1d613108"
      },
      "source": [
        "action"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sFPzMx2SHHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84e10341-a9a2-49b1-8cbf-82c4c8275b42"
      },
      "source": [
        "np.random.choice([1,2,3], size=1, replace=True, p=(0.1, 0.5, 0.4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS_8MxJTU9fC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = np.empty(0).reshape(0,dimen)\n",
        "states = np.vstack([states, state])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk6Qe82zVIIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb26abf1-132f-4c25-8851-b6ed9d87900d"
      },
      "source": [
        "states"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04977838,  0.04408428, -0.01042855,  0.003663  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}